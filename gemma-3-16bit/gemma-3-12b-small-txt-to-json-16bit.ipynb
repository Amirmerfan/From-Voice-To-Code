{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOgnnqV6e6NscFRlC3Ez2KJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4887c377664d47708d17fd666c79c47e":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_38fe26e02c3c4e168f2d0caf97abe171"}},"24b810cb72d04d2e8ecb7fea6a724d0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1b04c52380449e1a89339a5a24d9b98","placeholder":"​","style":"IPY_MODEL_fc0fbc09572648a8b1305ea4a8bc44da","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"e9aafbb2ea7c48799462b0439721c34a":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_e1c176acaf764699a171058e8e013bc0","placeholder":"​","style":"IPY_MODEL_0c6b7c2146fc4bf8b95da13115ea3773","value":""}},"5aba45c9eafd43a0b37bbfd9a52d0e1c":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_ab3637bff22e4a2395877e84d761c520","style":"IPY_MODEL_cc9108f5f7fe42b5b05e44470a5ab8de","value":true}},"42da83c168ed429d87a3fddd66116cf5":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_6bf1005269784f0683796fa6d3d873cd","style":"IPY_MODEL_9abccb010d0e4620a3da3eb4298b187b","tooltip":""}},"fdd063dc7236467a99a41693fd40beb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_009dcd48e213409d85dc3f7c5d971ae0","placeholder":"​","style":"IPY_MODEL_e2aab9da56c84ce8bdb6b3200cf2e464","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"38fe26e02c3c4e168f2d0caf97abe171":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"d1b04c52380449e1a89339a5a24d9b98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0fbc09572648a8b1305ea4a8bc44da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1c176acaf764699a171058e8e013bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c6b7c2146fc4bf8b95da13115ea3773":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab3637bff22e4a2395877e84d761c520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc9108f5f7fe42b5b05e44470a5ab8de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bf1005269784f0683796fa6d3d873cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9abccb010d0e4620a3da3eb4298b187b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"009dcd48e213409d85dc3f7c5d971ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2aab9da56c84ce8bdb6b3200cf2e464":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56b22654b8aa400096ecd38a8ae7595c":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d4dcec6c2f4ae0ab6d9bed4d8ec4d9","placeholder":"​","style":"IPY_MODEL_3761df8eb1f548958123fc009e4b2a26","value":"Connecting..."}},"e5d4dcec6c2f4ae0ab6d9bed4d8ec4d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3761df8eb1f548958123fc009e4b2a26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c7533782226450097699658f52937f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a33ce5644c341f4a7333765c2e1dc5a","IPY_MODEL_8cb6ccf478be4d25996dd11f097e36ca","IPY_MODEL_a8425eea097e4dc6a1d896cb28ff8960"],"layout":"IPY_MODEL_159a77056a0048a4896c6b3f4ff07d67"}},"1a33ce5644c341f4a7333765c2e1dc5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_390cf751c8d141cd951cd3428c2fba43","placeholder":"​","style":"IPY_MODEL_df33ea6d07c4439e989461762fec1aca","value":"Loading checkpoint shards: 100%"}},"8cb6ccf478be4d25996dd11f097e36ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2cc4a174a124dbd8049bc48570fb14d","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12cce52abfd4400d96c1b082046b94c8","value":5}},"a8425eea097e4dc6a1d896cb28ff8960":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaed3333fe0d4fe59986a38a180da89f","placeholder":"​","style":"IPY_MODEL_879bf6abe17741e0899495b8243716e2","value":" 5/5 [00:07&lt;00:00,  1.42s/it]"}},"159a77056a0048a4896c6b3f4ff07d67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390cf751c8d141cd951cd3428c2fba43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df33ea6d07c4439e989461762fec1aca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2cc4a174a124dbd8049bc48570fb14d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12cce52abfd4400d96c1b082046b94c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaed3333fe0d4fe59986a38a180da89f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"879bf6abe17741e0899495b8243716e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bea790d4d3d64bc3bc89e4039f7d3919":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95271eeaf1964c9490c4ddeba423c8e7","IPY_MODEL_ffe90d4297c3462b8d5e7eb088bbda93","IPY_MODEL_c60782f83ba24645a0ba078e0eb561f4"],"layout":"IPY_MODEL_63fa12f8d0d240469f4c2472ff28d6a0"}},"95271eeaf1964c9490c4ddeba423c8e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f369b01a0a9491b876733bc5d00b033","placeholder":"​","style":"IPY_MODEL_252ee1aacfa3401e8eb00e8c2c9ac981","value":"Loading checkpoint shards: 100%"}},"ffe90d4297c3462b8d5e7eb088bbda93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bce3e9179e84a44b849f498d69415ca","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b3fd9e6153e4fd484aa1639d2dfc28a","value":5}},"c60782f83ba24645a0ba078e0eb561f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a610970b8f6d452797b25254c0bc65f3","placeholder":"​","style":"IPY_MODEL_f770e457de4746899e3a7632a42f7a86","value":" 5/5 [00:07&lt;00:00,  1.46s/it]"}},"63fa12f8d0d240469f4c2472ff28d6a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f369b01a0a9491b876733bc5d00b033":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"252ee1aacfa3401e8eb00e8c2c9ac981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bce3e9179e84a44b849f498d69415ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b3fd9e6153e4fd484aa1639d2dfc28a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a610970b8f6d452797b25254c0bc65f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f770e457de4746899e3a7632a42f7a86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0t_Yux_uO0Et","executionInfo":{"status":"ok","timestamp":1745699802487,"user_tz":-180,"elapsed":3715,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}}},"outputs":[],"source":["!pip install -q -U transformers datasets accelerate peft trl bitsandbytes scipy"]},{"cell_type":"code","source":["import torch\n","import os\n","from datasets import Dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, PeftModel, get_peft_model\n","from trl import SFTTrainer\n","\n","from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["4887c377664d47708d17fd666c79c47e","24b810cb72d04d2e8ecb7fea6a724d0b","e9aafbb2ea7c48799462b0439721c34a","5aba45c9eafd43a0b37bbfd9a52d0e1c","42da83c168ed429d87a3fddd66116cf5","fdd063dc7236467a99a41693fd40beb3","38fe26e02c3c4e168f2d0caf97abe171","d1b04c52380449e1a89339a5a24d9b98","fc0fbc09572648a8b1305ea4a8bc44da","e1c176acaf764699a171058e8e013bc0","0c6b7c2146fc4bf8b95da13115ea3773","ab3637bff22e4a2395877e84d761c520","cc9108f5f7fe42b5b05e44470a5ab8de","6bf1005269784f0683796fa6d3d873cd","9abccb010d0e4620a3da3eb4298b187b","009dcd48e213409d85dc3f7c5d971ae0","e2aab9da56c84ce8bdb6b3200cf2e464","56b22654b8aa400096ecd38a8ae7595c","e5d4dcec6c2f4ae0ab6d9bed4d8ec4d9","3761df8eb1f548958123fc009e4b2a26"]},"id":"oauJKOX-O1vr","executionInfo":{"status":"ok","timestamp":1745699814099,"user_tz":-180,"elapsed":11611,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"b2ee0abd-36b7-4a1e-ba2a-e9130eb26605"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4887c377664d47708d17fd666c79c47e"}},"metadata":{}}]},{"cell_type":"code","source":["model_id = \"google/gemma-3-12b-it\"\n","\n","new_model_name = \"gemma-3-12b-it-small-json-16bit\""],"metadata":{"id":"WOlNO-1cPGNJ","executionInfo":{"status":"ok","timestamp":1745699815049,"user_tz":-180,"elapsed":2,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","eos_token = tokenizer.eos_token\n","\n","print(f\"EOS Token: {eos_token}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMPvP9A8Qv6M","executionInfo":{"status":"ok","timestamp":1745699824574,"user_tz":-180,"elapsed":2957,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"01819f26-5751-4e8c-b441-82c78a7e7c6c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["EOS Token: <eos>\n"]}]},{"cell_type":"code","source":["print(f\"Sample Data Point (check EOS):\\n{train_dataset[0]['formatted_text']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4WfKiE9Q1cJ","executionInfo":{"status":"ok","timestamp":1745696941199,"user_tz":-180,"elapsed":9,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"679cdfde-6106-4094-993b-839afb07a4dd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Data Point (check EOS):\n","Convert the following food order into JSON format using this structure:\n","[\n","  { \"customizations\": [\"Customization 1\", \"Customization 2\"], \"name\": \"Item Name\" },\n","  { \"customizations\": [], \"name\": \"Another Item\" }\n","]:\n","Get me a lemonade, a lemon meringue pie, and add extra toppings of chocolate chips, berries, and nuts.\n","[{\"customizations\":[],\"name\":\"Lemonade\"},{\"customizations\":[],\"name\":\"Lemon Meringue Pie\"},{\"customizations\":[\"Chocolate Chips\",\"Berries\",\"Nuts\"],\"name\":\"Extra Topping\"}]<eos>\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = train_dataset.to_pandas()\n","num_duplicates = df.duplicated().sum()\n","num_duplicates"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHMRQESpQdmO","executionInfo":{"status":"ok","timestamp":1745696941203,"user_tz":-180,"elapsed":3,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"9563c47a-0466-487d-8c24-b1dcfbcba23d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["np.int64(0)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from datasets import load_dataset\n","import json\n","\n","dataset_id = \"iTzMiNOS/voice-orders-small-clean-12k\"\n","split_name = \"train\"\n","\n","print(f\"Loading dataset '{dataset_id}' (split: '{split_name}')...\")\n","dataset = load_dataset(dataset_id, split=split_name)\n","\n","columns_to_keep = [\"transcribed_text\", \"items\", \"speaker\"]\n","dataset = dataset.remove_columns([col for col in dataset.column_names if col not in columns_to_keep])\n","\n","dataset = dataset.select(range(min(1200, len(dataset))))\n","\n","print(f\"Dataset loaded: {dataset}\")\n","\n","prefix = \"\"\"Convert the following food order into JSON format using this structure:\n","[\n","  { \"customizations\": [\"Customization 1\", \"Customization 2\"], \"name\": \"Item Name\" },\n","  { \"customizations\": [], \"name\": \"Another Item\" }\n","]:\n","\"\"\"\n","\n","print(\"Splitting dataset into train and validation sets...\")\n","train_val_split = dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = train_val_split['train']\n","validation_data = train_val_split['test']\n","\n","print(f\"Train set size: {len(train_data)}\")\n","print(f\"Validation set size: {len(validation_data)}\")\n","\n","def format_data_for_sft(example):\n","    text = example[\"transcribed_text\"]\n","    items_data = example[\"items\"]\n","    json_string = json.dumps(items_data, separators=(',', ':'))\n","    if 'tokenizer' not in globals():\n","        raise NameError(\"Tokenizer not found. Please run the tokenizer loading cell (Cell 5) first.\")\n","    eos = tokenizer.eos_token\n","    formatted_string = f\"{prefix}{text}\\n{json_string}{eos}\"\n","    return {\"formatted_text\": formatted_string}\n","\n","if 'tokenizer' in globals():\n","    print(\"Applying formatting function to the datasets...\")\n","    train_dataset = train_data.map(format_data_for_sft, remove_columns=train_data.column_names)\n","    validation_dataset = validation_data.map(format_data_for_sft, remove_columns=validation_data.column_names) # Process validation data too!\n","    print(\"Dataset formatting complete.\")\n","    print(f\"Train dataset features: {train_dataset.features}\")\n","    print(f\"Validation dataset features: {validation_dataset.features}\")\n","else:\n","    print(\"WARNING: Tokenizer not loaded yet. Re-run Cell 5 and this cell's mapping part.\")\n","    train_dataset = None\n","    validation_dataset = None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KRwH_2IPOiM","executionInfo":{"status":"ok","timestamp":1745699830452,"user_tz":-180,"elapsed":5872,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"c1246326-2e2f-4a31-a5f9-a3279adbc2fe"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset 'iTzMiNOS/voice-orders-small-clean-12k' (split: 'train')...\n","Dataset loaded: Dataset({\n","    features: ['transcribed_text', 'speaker', 'items'],\n","    num_rows: 1200\n","})\n","Splitting dataset into train and validation sets...\n","Train set size: 1080\n","Validation set size: 120\n","Applying formatting function to the datasets...\n","Dataset formatting complete.\n","Train dataset features: {'formatted_text': Value(dtype='string', id=None)}\n","Validation dataset features: {'formatted_text': Value(dtype='string', id=None)}\n"]}]},{"cell_type":"code","source":["validation_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huaLCLwqlEaC","executionInfo":{"status":"ok","timestamp":1745699830460,"user_tz":-180,"elapsed":3,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"b5304501-5dbf-46b6-b001-4ffb339443e9"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['transcribed_text', 'speaker', 'items'],\n","    num_rows: 120\n","})"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n","  print(\"GPU supports bfloat16, using torch.bfloat16 for model loading and training.\")\n","  model_dtype = torch.bfloat16\n","else:\n","  print(\"GPU does not support bfloat16, using torch.float16 for model loading and training.\")\n","  model_dtype = torch.float16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Il8nrSziRtqf","executionInfo":{"status":"ok","timestamp":1745699836839,"user_tz":-180,"elapsed":30,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"d18a524d-1f79-44d4-9ca4-08d393d6aa7e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU supports bfloat16, using torch.bfloat16 for model loading and training.\n"]}]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=model_dtype,\n","    device_map=\"auto\",\n",")\n","\n","print(f\"Base model loaded in {model_dtype}.\")\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6c7533782226450097699658f52937f7","1a33ce5644c341f4a7333765c2e1dc5a","8cb6ccf478be4d25996dd11f097e36ca","a8425eea097e4dc6a1d896cb28ff8960","159a77056a0048a4896c6b3f4ff07d67","390cf751c8d141cd951cd3428c2fba43","df33ea6d07c4439e989461762fec1aca","b2cc4a174a124dbd8049bc48570fb14d","12cce52abfd4400d96c1b082046b94c8","eaed3333fe0d4fe59986a38a180da89f","879bf6abe17741e0899495b8243716e2"]},"id":"makDnYpKT9jy","executionInfo":{"status":"ok","timestamp":1745698194099,"user_tz":-180,"elapsed":8515,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"7102ed74-518c-42d6-8d63-928ae4bbaf58"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7533782226450097699658f52937f7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Base model loaded in torch.bfloat16.\n","Gemma3ForConditionalGeneration(\n","  (vision_tower): SiglipVisionModel(\n","    (vision_model): SiglipVisionTransformer(\n","      (embeddings): SiglipVisionEmbeddings(\n","        (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n","        (position_embedding): Embedding(4096, 1152)\n","      )\n","      (encoder): SiglipEncoder(\n","        (layers): ModuleList(\n","          (0-26): 27 x SiglipEncoderLayer(\n","            (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n","            (self_attn): SiglipAttention(\n","              (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n","              (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n","              (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n","              (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n","            )\n","            (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n","            (mlp): SiglipMLP(\n","              (activation_fn): PytorchGELUTanh()\n","              (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n","              (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n","            )\n","          )\n","        )\n","      )\n","      (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n","    )\n","  )\n","  (multi_modal_projector): Gemma3MultiModalProjector(\n","    (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n","    (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n","  )\n","  (language_model): Gemma3ForCausalLM(\n","    (model): Gemma3TextModel(\n","      (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 3840, padding_idx=0)\n","      (layers): ModuleList(\n","        (0-47): 48 x Gemma3DecoderLayer(\n","          (self_attn): Gemma3Attention(\n","            (q_proj): Linear(in_features=3840, out_features=4096, bias=False)\n","            (k_proj): Linear(in_features=3840, out_features=2048, bias=False)\n","            (v_proj): Linear(in_features=3840, out_features=2048, bias=False)\n","            (o_proj): Linear(in_features=4096, out_features=3840, bias=False)\n","            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n","            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n","          )\n","          (mlp): Gemma3MLP(\n","            (gate_proj): Linear(in_features=3840, out_features=15360, bias=False)\n","            (up_proj): Linear(in_features=3840, out_features=15360, bias=False)\n","            (down_proj): Linear(in_features=15360, out_features=3840, bias=False)\n","            (act_fn): PytorchGELUTanh()\n","          )\n","          (input_layernorm): Gemma3RMSNorm((3840,), eps=1e-06)\n","          (post_attention_layernorm): Gemma3RMSNorm((3840,), eps=1e-06)\n","          (pre_feedforward_layernorm): Gemma3RMSNorm((3840,), eps=1e-06)\n","          (post_feedforward_layernorm): Gemma3RMSNorm((3840,), eps=1e-06)\n","        )\n","      )\n","      (norm): Gemma3RMSNorm((3840,), eps=1e-06)\n","      (rotary_emb): Gemma3RotaryEmbedding()\n","      (rotary_emb_local): Gemma3RotaryEmbedding()\n","    )\n","    (lm_head): Linear(in_features=3840, out_features=262208, bias=False)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["peft_config = LoraConfig(\n","    lora_alpha=128,\n","    lora_dropout=0.05,\n","    r=32,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","    ],\n",")"],"metadata":{"id":"A8Ze6lVwT90c","executionInfo":{"status":"ok","timestamp":1745698194107,"user_tz":-180,"elapsed":8,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from trl import SFTConfig\n","\n","sft_config = SFTConfig(\n","     output_dir=new_model_name,\n","     num_train_epochs=3,\n","     per_device_train_batch_size=2,\n","     gradient_accumulation_steps=4,\n","     optim=\"paged_adamw_8bit\",\n","     eval_strategy=\"steps\",\n","     eval_steps=100,\n","     logging_steps=10,\n","     learning_rate=5e-5,\n","     weight_decay=0.001,\n","     fp16=(model_dtype==torch.float16),\n","     bf16=(model_dtype==torch.bfloat16),\n","     max_grad_norm=0.3,\n","     max_steps=-1,\n","     warmup_ratio=0.03,\n","     group_by_length=True,\n","     lr_scheduler_type=\"cosine\",\n","     report_to=\"tensorboard\",\n","     save_strategy=\"steps\",\n","     save_steps=100,\n","     save_total_limit=2,\n","     load_best_model_at_end=True,\n","     metric_for_best_model=\"eval_loss\",\n","     greater_is_better=False,\n","     max_seq_length=1024,\n","     packing=False,\n","     dataset_text_field=\"formatted_text\",\n","     push_to_hub=True,\n","     hub_model_id=f\"iTzMiNOS/{new_model_name}\",\n",")\n","\n","print(\"SFTConfig configured.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KV0bvfUOT6f6","executionInfo":{"status":"ok","timestamp":1745698194129,"user_tz":-180,"elapsed":15,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"e100731b-737e-4a6e-f08a-994e5db6e7d6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["SFTConfig configured.\n"]}]},{"cell_type":"code","source":["if 'train_dataset' not in globals() or 'validation_dataset' not in globals() or train_dataset is None or validation_dataset is None:\n","     raise ValueError(\"Training or Validation dataset not found or not processed. Please ensure Cell 4 ran correctly after loading the tokenizer.\")\n","if 'model' not in globals():\n","      raise ValueError(\"Model not loaded.\")\n","if 'tokenizer' not in globals():\n","      raise ValueError(\"Tokenizer not loaded.\")\n","if 'sft_config' not in globals():\n","      raise ValueError(\"SFTConfig not defined.\")\n","if 'peft_config' not in globals():\n","      raise ValueError(\"peft_config not defined.\")\n","\n","tokenizer.chat_template = None\n","print(\"Attempting SFTTrainer initialization using SFTConfig...\")\n","try:\n","    trainer = SFTTrainer(\n","        model=model,\n","        args=sft_config,\n","        train_dataset=train_dataset,\n","        eval_dataset=validation_dataset,\n","        peft_config=peft_config,\n","        processing_class=tokenizer,\n","    )\n","    print(\"SFTTrainer initialized successfully using SFTConfig!\")\n","\n","except TypeError as e:\n","    print(f\"SFTTrainer STILL FAILED with TypeError: {e}\")\n","    print(\"Check if 'tokenizer' is now the unexpected argument.\")\n","except Exception as e:\n","    print(f\"SFTTrainer FAILED with another error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhVLga2cVJbT","executionInfo":{"status":"ok","timestamp":1745698198267,"user_tz":-180,"elapsed":4084,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"ace4de76-ef58-49b4-a8c0-caca7a438b62"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting SFTTrainer initialization using SFTConfig...\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["SFTTrainer initialized successfully using SFTConfig!\n"]}]},{"cell_type":"code","source":["print(\"Starting fine-tuning...\")\n","trainer.train()\n","print(\"Fine-tuning finished.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"uTOUTxlAYr6v","executionInfo":{"status":"ok","timestamp":1745699278793,"user_tz":-180,"elapsed":1080155,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"e17dbc45-2bcb-42ea-83b9-154149177bc9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting fine-tuning...\n"]},{"output_type":"stream","name":"stderr","text":["It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [405/405 17:22, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.819600</td>\n","      <td>0.260021</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.697000</td>\n","      <td>0.222391</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.574400</td>\n","      <td>0.214316</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.554800</td>\n","      <td>0.212726</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fine-tuning finished.\n"]}]},{"cell_type":"code","source":["print(f\"Saving fine-tuned adapters to ./{new_model_name}\")\n","trainer.model.save_pretrained(new_model_name)\n","tokenizer.save_pretrained(new_model_name)\n","print(\"Adapters and tokenizer saved.\")\n","\n","# Optional: Clean up memory\n","# del model\n","# del trainer\n","# torch.cuda.empty_cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0ErYPM8Vb2N","executionInfo":{"status":"ok","timestamp":1745699366197,"user_tz":-180,"elapsed":1949,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"d62cbf61-500c-4521-9c19-ab2f505a1dfc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving fine-tuned adapters to ./gemma-3-12b-it-small-json-16bit\n","Adapters and tokenizer saved.\n"]}]},{"cell_type":"code","source":["# Cell: Inference and Evaluation (Batched & GPU Ensured & Fence Cleaning)\n","\n","import json\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import (\n","    pipeline,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    logging\n",")\n","from peft import PeftModel\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from difflib import SequenceMatcher\n","import torch\n","import gc\n","import os\n","import math\n","import numpy as np\n","import re # Import regex for cleaning fences\n","\n","# --- Configuration ---\n","base_model_id = \"google/gemma-3-12b-it\"\n","adapter_model_id = f\"iTzMiNOS/{new_model_name}\"\n","prefix = \"\"\"Convert the following food order into JSON format using this structure:\n","[\n","  { \"customizations\": [\"Customization 1\", \"Customization 2\"], \"name\": \"Item Name\" },\n","  { \"customizations\": [], \"name\": \"Another Item\" }\n","]:\n","\"\"\"\n","inference_batch_size = 16\n","\n","if not torch.cuda.is_available():\n","     raise SystemError(\"CUDA is not available. This script requires a GPU.\")\n","else:\n","     device_name = torch.cuda.get_device_name(0)\n","     print(f\"CUDA is available. Using GPU: {device_name}\")\n","     if torch.cuda.get_device_capability(0)[0] >= 8:\n","         print(\"GPU supports bfloat16, using torch.bfloat16 for inference.\")\n","         model_dtype_inference = torch.bfloat16\n","     else:\n","         print(\"GPU does not support bfloat16, using torch.float16 for inference.\")\n","         model_dtype_inference = torch.float16\n","     device = 0\n","\n","# --- Memory Cleanup ---\n","print(\"Cleaning up memory before loading...\")\n","gc.collect()\n","torch.cuda.empty_cache()\n","print(\"CUDA cache cleared.\")\n","\n","# --- Load Tokenizer ---\n","print(f\"Loading tokenizer from {base_model_id}...\")\n","tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"left\"\n","eos_token = tokenizer.eos_token\n","assert tokenizer.pad_token_id is not None, \"Tokenizer pad_token_id is not set!\"\n","print(\"Tokenizer loaded.\")\n","\n","# --- Load Base Model ---\n","print(f\"Loading base model ({base_model_id}) in {model_dtype_inference}\")\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,\n","    torch_dtype=model_dtype_inference,\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")\n","print(f\"Base model loaded. Device map: {model.hf_device_map}\")\n","\n","# --- Load LoRA Adapter ---\n","print(f\"Loading LoRA adapter ({adapter_model_id}) onto the base model...\")\n","try:\n","    model = PeftModel.from_pretrained(model, adapter_model_id)\n","    print(\"LoRA adapter loaded successfully.\")\n","    print(\"Attempting to merge LoRA adapter...\")\n","    try:\n","        model = model.merge_and_unload()\n","        print(\"LoRA adapter merged successfully.\")\n","    except Exception as e:\n","        print(f\"⚠️ Could not merge LoRA adapter: {e}. Proceeding with PEFT model.\")\n","except Exception as e:\n","     print(f\"❌ Failed to load LoRA adapter: {e}\")\n","     raise e\n","\n","# --- Build the Inference Pipeline ---\n","logging.set_verbosity(logging.CRITICAL)\n","print(\"Building text-generation pipeline...\")\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n",")\n","if hasattr(pipe, 'device'): print(f\"Pipeline device: {pipe.device}\")\n","else: print(\"Pipeline device managed by model's device_map.\")\n","\n","# --- Load Validation Data ---\n","if 'validation_data' not in globals():\n","     print(\"validation_data not found, attempting reload...\")\n","     from datasets import load_dataset\n","     dataset_id = \"iTzMiNOS/voice-orders-small-clean-12k\"\n","     split_name = \"train\"\n","     dataset = load_dataset(dataset_id, split=split_name)\n","     columns_to_keep = [\"transcribed_text\", \"items\", \"speaker\"]\n","     dataset = dataset.remove_columns([col for col in dataset.column_names if col not in columns_to_keep])\n","     dataset = dataset.select(range(min(1200, len(dataset))))\n","     train_val_split = dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n","     validation_data = train_val_split['test']\n","     print(\"Reloaded and split dataset.\")\n","\n","df = validation_data.to_pandas()\n","print(f\"Loaded validation data with {len(df)} rows.\")\n","\n","# --- Convert Numpy arrays in 'items' column ---\n","def deep_convert(obj):\n","    if isinstance(obj, dict):\n","        return {k: deep_convert(v) for k, v in obj.items()}\n","    elif isinstance(obj, list):\n","        return [deep_convert(v) for v in obj]\n","    elif isinstance(obj, np.ndarray):\n","        return deep_convert(obj.tolist())\n","    else:\n","        return obj\n","\n","df['items'] = df['items'].apply(deep_convert)\n","print(\"Conversion complete.\")\n","\n","\n","# --- ***** UPDATED: Function for Robust JSON Parsing (Handles Fences) ***** ---\n","def parse_json_robustly(generated_text):\n","    \"\"\"Attempts to extract and parse JSON, handling optional markdown fences.\"\"\"\n","    json_str = None\n","    try:\n","        # Find the start of the first list or object\n","        first_bracket = generated_text.find('[')\n","        first_brace = generated_text.find('{')\n","\n","        start_index = -1\n","        if first_bracket != -1 and (first_brace == -1 or first_bracket < first_brace):\n","            start_index = first_bracket\n","            start_char = '['\n","            end_char = ']'\n","        elif first_brace != -1:\n","            start_index = first_brace\n","            start_char = '{'\n","            end_char = '}'\n","        else:\n","             # Neither bracket nor brace found - maybe it's ONLY fences?\n","             # Try finding fences directly if no brace/bracket\n","             fence_match = re.search(r\"`{3}(json)?\\s*([\\[\\{])\", generated_text)\n","             if fence_match:\n","                 start_index = fence_match.end() -1 # Start at the brace/bracket\n","                 start_char = fence_match.group(2)\n","                 end_char = ']' if start_char == '[' else '}'\n","             else:\n","                # Give up if no structure found\n","                # print(f\"Debug: No JSON start ('[' or '{{') found. Output: {generated_text}\")\n","                return None\n","\n","        # Find the corresponding closing character using balancing\n","        open_count = 0\n","        end_index = -1\n","        # Check if start_index is valid before proceeding\n","        if start_index >= 0 and start_index < len(generated_text):\n","            for i in range(start_index, len(generated_text)):\n","                if generated_text[i] == start_char:\n","                    open_count += 1\n","                elif generated_text[i] == end_char:\n","                    open_count -= 1\n","                if open_count == 0:\n","                    end_index = i\n","                    break\n","        else:\n","             # Handle invalid start_index if fence logic above failed unusually\n","             print(f\"Debug: Invalid start_index {start_index}. Output: {generated_text}\")\n","             return None\n","\n","\n","        if end_index == -1:\n","            # print(f\"Debug: No matching closing bracket/brace. Output: {generated_text}\")\n","            return None\n","\n","        # Extract the potential JSON substring\n","        json_str = generated_text[start_index : end_index + 1]\n","\n","        # Clean leading/trailing whitespace that might remain\n","        json_str = json_str.strip()\n","\n","        # --- Attempt to parse the extracted & cleaned string ---\n","        json_data = json.loads(json_str)\n","        return json_data\n","\n","    except json.JSONDecodeError as e:\n","        # Add logging for parse failures, include the string attempted\n","        print(f\"Warning: Could not parse JSON: {e}.\")\n","        print(f\"Attempted to parse (after extraction): '{json_str}'\")\n","        # print(f\"Original Generated Text: {generated_text}\") # Uncomment for deeper debugging\n","        return None\n","    except Exception as e:\n","        # Catch any other unexpected errors during parsing\n","        print(f\"Warning: Unexpected error during JSON parsing: {e}.\")\n","        print(f\"Attempted to parse (after extraction): '{json_str}'\")\n","        # print(f\"Original Generated Text: {generated_text}\") # Uncomment for deeper debugging\n","        return None\n","# --- End Updated Function ---\n","\n","\n","# --- Apply Inference with Batching (Unchanged) ---\n","print(f\"Running batched inference (batch size: {inference_batch_size})...\")\n","all_prompts = [f\"{prefix}{text}\" for text in df['transcribed_text']]\n","all_results = []\n","num_batches = math.ceil(len(all_prompts) / inference_batch_size)\n","for i in tqdm(range(0, len(all_prompts), inference_batch_size), desc=\"Inference Batches\", total=num_batches):\n","    batch_prompts = all_prompts[i:i+inference_batch_size]\n","    try:\n","        batch_outputs = pipe(batch_prompts, max_new_tokens=500, return_full_text=False, pad_token_id=tokenizer.eos_token_id, batch_size=len(batch_prompts))\n","        for output_list in batch_outputs:\n","            if output_list and isinstance(output_list, list):\n","                 generated_text = output_list[0][\"generated_text\"].strip()\n","                 parsed_json = parse_json_robustly(generated_text) # Use updated parser\n","                 all_results.append(parsed_json)\n","            else: print(f\"Warning: Unexpected output format: {output_list}\"); all_results.append(None)\n","    except Exception as e:\n","        print(f\"\\n--- ERROR during batch {i // inference_batch_size + 1} --- Error: {e}\")\n","        all_results.extend([None] * len(batch_prompts))\n","if len(all_results) != len(all_prompts):\n","     print(f\"Warning: Result count mismatch! Padding with None.\")\n","     all_results.extend([None] * (len(all_prompts) - len(all_results)))\n","df['predicted_items'] = all_results\n","print(\"Inference complete.\")\n","\n","def to_lower(obj):\n","    if isinstance(obj, str):\n","        return obj.lower()  # Convert strings to lowercase\n","    elif isinstance(obj, dict):\n","        return {k: to_lower(v) for k, v in obj.items()}  # Apply recursively for dictionaries\n","    elif isinstance(obj, list):\n","        return [to_lower(v) for v in obj]  # Apply recursively for lists\n","    else:\n","        return obj\n","\n","# --- Comparison Metric (Unchanged) ---\n","def similarity_score(pred, target):\n","    if pred is None or target is None:\n","        return 0.0\n","    try:\n","        # Convert both the prediction and target to lowercase\n","        pred = to_lower(pred)\n","        target = to_lower(target)\n","\n","        # Convert the structures into strings\n","        pred_str = json.dumps(pred, sort_keys=True, separators=(',', ':'))\n","        target_str = json.dumps(target, sort_keys=True, separators=(',', ':'))\n","\n","        return SequenceMatcher(None, pred_str, target_str).ratio()\n","    except Exception as e:\n","        print(f\"Error calculating similarity: Pred={pred}, Target={target}, Error={e}\")\n","        return 0.0\n","# --- Calculate Metrics (Unchanged) ---\n","print(\"Calculating metrics...\")\n","df['similarity'] = df.apply(lambda row: similarity_score(row['predicted_items'], row['items']), axis=1)\n","df['exact_match'] = df.apply(lambda row:\n","                             row['predicted_items'] is not None and\n","                             row['items'] is not None and\n","                             to_lower(row['predicted_items']) == to_lower(row['items']),\n","                             axis=1)\n","\n","average_similarity = df['similarity'].mean()\n","exact_match_accuracy = df['exact_match'].mean()\n","\n","print(\"\\n--- Evaluation Results ---\")\n","print(f\"🔍 Average Similarity Score: {average_similarity:.4f}\")\n","print(f\"✅ Exact Match Accuracy: {exact_match_accuracy:.2%}\")\n","\n","# --- Display Mismatches (Unchanged) ---\n","print(\"\\n--- Low Similarity Examples (< 0.8) ---\")\n","low_sim_df = df[df['similarity'] < 0.8][['transcribed_text', 'items', 'predicted_items', 'similarity']]\n","print(low_sim_df.to_string())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624,"referenced_widgets":["bea790d4d3d64bc3bc89e4039f7d3919","95271eeaf1964c9490c4ddeba423c8e7","ffe90d4297c3462b8d5e7eb088bbda93","c60782f83ba24645a0ba078e0eb561f4","63fa12f8d0d240469f4c2472ff28d6a0","1f369b01a0a9491b876733bc5d00b033","252ee1aacfa3401e8eb00e8c2c9ac981","2bce3e9179e84a44b849f498d69415ca","7b3fd9e6153e4fd484aa1639d2dfc28a","a610970b8f6d452797b25254c0bc65f3","f770e457de4746899e3a7632a42f7a86"]},"id":"QNAjREpBvHM9","executionInfo":{"status":"ok","timestamp":1745699928345,"user_tz":-180,"elapsed":85758,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}},"outputId":"ae9b279f-3366-44e6-e9f6-a577e893c811"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available. Using GPU: NVIDIA A100-SXM4-40GB\n","GPU supports bfloat16, using torch.bfloat16 for inference.\n","Cleaning up memory before loading...\n","CUDA cache cleared.\n","Loading tokenizer from google/gemma-3-12b-it...\n","Tokenizer loaded.\n","Loading base model (google/gemma-3-12b-it) in torch.bfloat16\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea790d4d3d64bc3bc89e4039f7d3919"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Base model loaded. Device map: {'': 0}\n","Loading LoRA adapter (iTzMiNOS/gemma-3-12b-it-small-json-16bit) onto the base model...\n","LoRA adapter loaded successfully.\n","Attempting to merge LoRA adapter...\n","LoRA adapter merged successfully.\n","Building text-generation pipeline...\n","Pipeline device: cuda:0\n","Loaded validation data with 120 rows.\n","Conversion complete.\n","Running batched inference (batch size: 16)...\n"]},{"output_type":"stream","name":"stderr","text":["Inference Batches: 100%|██████████| 8/8 [01:10<00:00,  8.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Inference complete.\n","Calculating metrics...\n","\n","--- Evaluation Results ---\n","🔍 Average Similarity Score: 0.9790\n","✅ Exact Match Accuracy: 83.33%\n","\n","--- Low Similarity Examples (< 0.8) ---\n","                                                                                                                                            transcribed_text                                                                                                                                                                                                                                                                               items                                                                                                                                                                                                                                                                         predicted_items  similarity\n","21                  Ordering a Caesar Salad with grilled shrimp, a Greek Salad with grilled chicken, an apple pie, and some extra blue cheese dipping sauce.  [{'customizations': ['Grilled Shrimp', 'Grilled Chicken', 'No Protein'], 'name': 'Caesar Salad'}, {'customizations': ['Grilled Chicken'], 'name': 'Greek Salad'}, {'customizations': [], 'name': 'Apple Pie'}, {'customizations': ['Blue Cheese'], 'name': 'Extra Dipping Sauce'}]                                       [{'customizations': ['Grilled Shrimp'], 'name': 'Caesar Salad'}, {'customizations': ['Grilled Chicken'], 'name': 'Greek Salad'}, {'customizations': [], 'name': 'Apple Pie'}, {'customizations': ['Blue Cheese'], 'name': 'Extra Dipping Sauce'}]    0.695652\n","44                                          Can I get a Chicken Soup with a lemon wedge and a Cream of Mushroom topped with chopped parsley and truffle oil?                                                                                                                                  [{'customizations': ['Lemon Wedge'], 'name': 'Chicken Soup'}, {'customizations': ['Chopped Parsley', 'Truffle Oil'], 'name': 'Cream of Mushroom'}]                       [{'customizations': ['Lemon Wedge'], 'name': 'Chicken Soup'}, {'customizations': ['Chopped Parsley', 'Truffle Oil'], 'name': 'Cream of Mushroom'}, {'customizations': [], 'name': 'Lemon Meringue Pie'}, {'customizations': [], 'name': 'Extra Ice Cream Scoop'}]    0.728232\n","53                                  Getting a mix of craft beer including IPA, pale ale, and lager along with some wine options, specifically rosÃ© and red.                                                                                                                                                       [{'customizations': ['IPA', 'Pale Ale', 'Lager'], 'name': 'Craft Beer'}, {'customizations': ['Rose', 'Red'], 'name': 'Wine'}]  [{'customizations': ['IPA', 'Pale Ale', 'Lager'], 'name': 'Craft Beer'}, {'customizations': ['Rose', 'Red'], 'name': 'Wine'}, {'customizations': ['Veggies', 'Mashed Potatoes', 'Rice'], 'name': 'Extra Side'}, {'customizations': ['Caramel', 'Vanilla'], 'name': 'Flavored Syrups'}]    0.618280\n","55               I'm ordering a Caesar Salad with no protein, a Fish and Chips that's crispy, Grilled Tofu with soy ginger, and an extra scoop of ice cream.    [{'customizations': ['No Protein', 'Grilled Chicken', 'Grilled Shrimp'], 'name': 'Caesar Salad'}, {'customizations': ['Crispy'], 'name': 'Fish and Chips'}, {'customizations': ['Soy Ginger'], 'name': 'Grilled Tofu'}, {'customizations': [], 'name': 'Extra Ice Cream Scoop'}]                             [{'customizations': ['No Protein'], 'name': 'Caesar Salad'}, {'customizations': ['Crispy', 'Extra Crispy'], 'name': 'Fish and Chips'}, {'customizations': ['Soy Ginger'], 'name': 'Grilled Tofu'}, {'customizations': [], 'name': 'Extra Ice Cream Scoop'}]    0.371429\n","65  I'll have the cream of mushroom with chopped parsley, a sweetened iced tea, a selection of rose, white, and red wine, and some extra cheese on the side.                                         [{'customizations': ['Chopped Parsley'], 'name': 'Cream of Mushroom'}, {'customizations': ['Sweetened'], 'name': 'Iced Tea'}, {'customizations': ['Rose', 'White', 'Red'], 'name': 'Wine'}, {'customizations': [], 'name': 'Extra Cheese'}]                              [{'customizations': ['Chopped Parsley'], 'name': 'Cream of Mushroom'}, {'customizations': ['Sweetened', 'Unsweetened'], 'name': 'Iced Tea'}, {'customizations': ['Rose', 'White', 'Red'], 'name': 'Wine'}, {'customizations': [], 'name': 'Extra Cheese'}]    0.666667\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["df.head(5)"],"metadata":{"id":"kHstVROE01Wu","executionInfo":{"status":"aborted","timestamp":1745697676281,"user_tz":-180,"elapsed":471373,"user":{"displayName":"Amir Erfan","userId":"17056904882617357694"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OB8j1aNkJuY_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe(prefix + , max_new_tokens=200, return_full_text=False, pad_token_id=tokenizer.eos_token_id)"],"metadata":{"id":"lX-XEg4D01oW"},"execution_count":null,"outputs":[]}]}